{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e97a8fa",
   "metadata": {},
   "source": [
    "#  DeblurGAN-v2\n",
    "\n",
    "In this Notebook, I have implemented DeblurGAN-v2 model and got the outputs as required after deblurring of image.\n",
    "\n",
    "DeblurGAN-v2 is a generative adversarial network (GAN) for single image motion deblurring. This model is based\n",
    "on a relativistic conditional GAN with a double-scale discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32495651",
   "metadata": {},
   "source": [
    "# 1.Preparation of Model\n",
    "\n",
    "**Importing the Required Packages** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openvino.runtime import Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb41ed",
   "metadata": {},
   "source": [
    "**Downloading the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1796bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the directory where model will be downloaded\n",
    "model_directory = Path(\"./model\").expanduser()\n",
    "\n",
    "# name of the model as named in Open Model Zoo\n",
    "model_name = \"deblurgan-v2\"\n",
    "\n",
    "download_command = (f\"omz_downloader --name {model_name} --output_dir {model_directory}\")\n",
    "! $download_command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1101a6",
   "metadata": {},
   "source": [
    "**Converting the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd9b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = \"FP16\"\n",
    "\n",
    "# setting the output path for the conversion\n",
    "converted_model_path = f\"{model_directory}/public/{model_name}/{precision}/{model_name}.xml\"\n",
    "\n",
    "if not os.path.exists(converted_model_path):\n",
    "    converting_command = f\"omz_converter --name {model_name} --download_dir {model_directory} --precisions {precision}\"\n",
    "    ! $converting_command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61a3f2d",
   "metadata": {},
   "source": [
    "# 2.Loading the Deblurgan-v2 Model\n",
    "\n",
    "As we have Downloaded and converted the Model, now we need to load the Model.\n",
    "\n",
    "This deblurgan-v2 Model takes the input image of shape (1,3,736,1312) in the shape format of(Batch Size, Channels, Height, Width) and output the image of same shape after deblurring it.\n",
    "\n",
    "Here we have loaded the model using ie_core.read_model and compiled it using ie_core.compile_model and gets information about the input shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc18dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie_core = Core()\n",
    "\n",
    "model = ie_core.read_model(model=converted_model_path)\n",
    "compiled_model = ie_core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "# get input and output nodes\n",
    "input_layer = next(iter(compiled_model.inputs))\n",
    "output_layer = next(iter(compiled_model.outputs))\n",
    "\n",
    "# get input size\n",
    "channels, height, width = list(input_layer.shape)[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8220e231",
   "metadata": {},
   "source": [
    "# 3. Loading and Preproceesing of Image\n",
    "\n",
    "Now we will make some functions to preprocess the image and prepare it for input. \n",
    "We will load the image, reshape it and pad it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ba0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bgr_to_rgb(src_img):\n",
    "    \"\"\"\n",
    "    This function converts BGR image to RGB image\n",
    "    It takes a BGR image input as numpy array and returns the RGB image\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(src_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def resizing(img):\n",
    "\n",
    "    \"\"\"\n",
    "    This funtion takes an image as input, reshape it(keeping the aspect ratio same)\n",
    "    to minimum width or minimum height(depending upon which will make the other dimension\n",
    "    smaller than input dimension) and then pad it to make it equal to the required input \n",
    "    dimenision and return the image of dimension(height ,width, channels)\n",
    "\n",
    "    While padding the image, this function also stores the coordinates where the actual part\n",
    "    of image is located in the padded image as to convert the output image back to the shape \n",
    "    of source image.\n",
    "\n",
    "    \"\"\"\n",
    "    h, w, _ = img.shape\n",
    "    crop_dims = []\n",
    "\n",
    "    maximum_width = (w * height) // h\n",
    "    if maximum_width <= width:\n",
    "        img = cv2.resize(img, (maximum_width, height))\n",
    "\n",
    "        left_padding = (width - maximum_width) // 2\n",
    "        right_padding = width - maximum_width - left_padding\n",
    "\n",
    "        crop_dims.append(0)\n",
    "        crop_dims.append(height)\n",
    "        crop_dims.append(left_padding + 1)\n",
    "        crop_dims.append(left_padding + maximum_width + 1)\n",
    "\n",
    "        img = np.pad(\n",
    "            img,\n",
    "            [(0, 0), (left_padding, right_padding), (0, 0)],\n",
    "            \"constant\",\n",
    "            constant_values=0,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        maximum_height = (h * width) // w\n",
    "        img = cv2.resize(img, (width, maximum_height))\n",
    "\n",
    "        top_padding = (height - maximum_height) // 2\n",
    "        bottom_padding = height - maximum_height - top_padding\n",
    "\n",
    "        crop_dims.append(top_padding + 1)\n",
    "        crop_dims.append(top_padding + maximum_height + 1)\n",
    "        crop_dims.append(0)\n",
    "        crop_dims.append(width)\n",
    "\n",
    "        img = np.pad(\n",
    "            img,\n",
    "            [(top_padding, bottom_padding), (0, 0), (0, 0)],\n",
    "            \"constant\",\n",
    "            constant_values=0,\n",
    "        )\n",
    "\n",
    "    return img, crop_dims\n",
    "\n",
    "\n",
    "def finalising_input_image(img):\n",
    "\n",
    "    \"\"\"\n",
    "    This function takes an image as input and first change its shape from (height, width, channels) \n",
    "    to (channels, height, width) and then expands its dimension to make the dimension equal \n",
    "    to input dimension i.e. (1, channels, height, width)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    img = np.moveaxis(img, 2, 0)\n",
    "    h, w, _ = img.shape\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def plot_image(img1, img2, title1, title2):\n",
    "    \"\"\"\n",
    "    This Function shows the image with the title given as input\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    if title2 == \"\":\n",
    "        plt.subplot(1, 1, 1)\n",
    "        plt.imshow(img1)\n",
    "        plt.title(title1)\n",
    "\n",
    "    else:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img1)\n",
    "        plt.title(title1)\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(img2)\n",
    "        plt.title(title2)\n",
    "\n",
    "\n",
    "# Taking input the source image\n",
    "src_img = cv2.imread(\"data/input/blurred.png\")\n",
    "\n",
    "# Converting it to RGB format\n",
    "src_img = convert_bgr_to_rgb(src_img)\n",
    "\n",
    "# Resizing the image\n",
    "resized_image, crop_dims = resizing(src_img)\n",
    "\n",
    "# Finalising the input image\n",
    "input_image = finalising_input_image(resized_image)\n",
    "\n",
    "# Showing the Source Image\n",
    "plot_image(src_img, None, \"Source Image\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31abff86",
   "metadata": {},
   "source": [
    "# 4. Inference and Getting the Result\n",
    "\n",
    "Now we will input the input_image in the compiled model and get the result_image from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving the processed input image in the model and getting the results\n",
    "result_image = compiled_model([input_image])[output_layer]\n",
    "print(f\"Model's output shape: {result_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3880dd6e",
   "metadata": {},
   "source": [
    "# 5. Post-processing of Output Image and Plotting the Result\n",
    "\n",
    "Now we will define a function to get the image of same shape as source image from the Model's Output.\n",
    "In this function, we will remove padding and reshape it to the shape of source image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_to_image(res, src_img, crop_dims):\n",
    "\n",
    "    \"\"\"\n",
    "    This function takes the result image as input along with the source image and croping dimensions\n",
    "    and first crops the image with the input cropping dimensions(to remove the padding) and\n",
    "    then reshape the result image to the dimension of source image.\n",
    "    \"\"\"\n",
    "\n",
    "    res = (res - res.min()) / (res.max() - res.min())  # to normalize\n",
    "    res = (res * 255).astype(np.uint8)\n",
    "\n",
    "    # Converting the result image into desired dimensions\n",
    "    res = res.reshape((channels, height, width))\n",
    "    res = np.moveaxis(res, 0, -1)\n",
    "    h, w, _ = src_img.shape\n",
    "    res = res[crop_dims[0] : crop_dims[1], crop_dims[2] : crop_dims[3]]\n",
    "    res = cv2.resize(res, (w, h))\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# Changing the shape of result image to source image\n",
    "result_image = result_to_image(result_image, src_img, crop_dims)\n",
    "print(f\"Final Output image shape: {result_image.shape}\")\n",
    "\n",
    "plot_image(src_img, result_image, \"Source Image\", \"Final Deblurred Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2e29cc",
   "metadata": {},
   "source": [
    "# 5. Saving the Result in a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12bcb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Output Directory\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "#converting the image to BGR\n",
    "result_image = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Saving the image\n",
    "cv2.imwrite(\"output/deblurred_image.png\",result_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
